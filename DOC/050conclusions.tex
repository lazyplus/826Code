In this project, we studied and explored several aspects of belief propagation. Specifically, we studied the principle of belief propagation and its convergent conditions and how to improve its convergence. We implemented convergence detection and message smoothing on PEGASUS implementation of BP. Experiment shows these two implementations work as expected.

We explored how to extend FastBP to multiclass using several different methods. 

We designed and performed general ECOC algorithm and one-vs-all algorithm on four networks. The result shows that \textbf{OVA} method gains best accuracy among two of the four networks, and is slightly better than the general ECOC method. It also shows that \textbf{OVA}’s performance is more stable than Multiclass BP, and gives more “smooth” predictions.

We also tried to approximate BP as an optimization problem, based on the assumption that the correlation matrix is close to an identity matrix. But there are still several problems exist. The first one is that the final solution to the formulated optimization problem still needs to be simplified. The second problem, how can we derive an upper bound for the distance between the solution to the optimization problem and the solution of the original Belief Propagation algorithm. Last but not least, a new approximation for the logarithm operation without any strict assumption may improve the accuracy of the approximation.